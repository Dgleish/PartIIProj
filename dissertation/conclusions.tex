\documentclass[diss.tex]{subfiles}

\begin{document}
\chapter{Conclusions}
\label{chap:conclusions}
The project was a success. I implemented a library for a P2P collaborative editing application using CRDTs, then showed by building a minimal user interface that it can be utilised properly. I also implemented a number of other extensions to my original proposal, including encryption, allowing communication over the Tor network, a contrasting data structure for the CRDT, and an undo-redo feature. I then showed that the application displayed reasonable memory usage and latency, so was suitable for use in a desktop application. My conclusion on reliability is somewhat weaker, but it seems that my work would not be responsible for a communication failure. However, I didn't have time to implement any special retry logic, so if a node is unreachable, the application gives up and moves on instead of trying more times.

In hindsight, the domain of the project was quite broad; I touched on areas of distributed systems, networking and security. It would have been nice to be able to focus more in-depth in one of these areas, for example looking at the different CRDT schemes more closely. That being said, I was able to go into sufficient detail to understand and implement the LSEQ scheme, which was the topic of a recent research paper, though I would have liked to explore its allocation strategies more, and see if I could come up with one of my own that performed better than their random-choice strategy.

There are a number of future directions this project could be taken in. Described here are ideas I would have liked to implement, but didn't have the time. Firstly, I was unable to implement the undo feature properly; as it is undoing the deletion of somebody else's character is prohibited, but using the principle of \cite{logootundo} this should be rectifiable. Another would be to focus on the CRDTs, and look at string-level editing (ie an atom is a sequence of characters, rather than just a single one), where strings can be dynamically split up into smaller strings, as in \cite{stringed}. This approach could save a lot in terms of memory usage. Alternatively, more work could be put into the networking side, and look at other ways of connecting peers together, to prevent the need for a fully connected graph, for example randomly dropping some of the $n^2$ links to get a sparser graph (as proposed in \cite{spray}). Also, work could be done to cryptographically sign operations sent over a network, so that the source of the operation could be verified. Finally, there is no way to save a document for editing later. Looking at formats for such files and any compression that could be done on them would be an interesting problem.








\end{document}